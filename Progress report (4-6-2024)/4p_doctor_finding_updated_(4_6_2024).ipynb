{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L6dPD-Wrta3x",
        "outputId": "23e66e71-fb80-41e0-9298-51f72396d68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting googletrans==4.0.0-rc1\n",
            "  Downloading googletrans-4.0.0rc1.tar.gz (20 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting httpx==0.13.3 (from googletrans==4.0.0-rc1)\n",
            "  Downloading httpx-0.13.3-py3-none-any.whl (55 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.1/55.1 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (2024.2.2)\n",
            "Collecting hstspreload (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hstspreload-2024.6.1-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx==0.13.3->googletrans==4.0.0-rc1) (1.3.1)\n",
            "Collecting chardet==3.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading chardet-3.0.4-py2.py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/133.4 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna==2.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading idna-2.10-py2.py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.8/58.8 kB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rfc3986<2,>=1.3 (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading rfc3986-1.5.0-py2.py3-none-any.whl (31 kB)\n",
            "Collecting httpcore==0.9.* (from httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading httpcore-0.9.1-py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.10,>=0.8 (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h11-0.9.0-py2.py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.6/53.6 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h2==3.* (from httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading h2-3.2.0-py2.py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.0/65.0 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting hyperframe<6,>=5.2.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hyperframe-5.2.0-py2.py3-none-any.whl (12 kB)\n",
            "Collecting hpack<4,>=3.0 (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans==4.0.0-rc1)\n",
            "  Downloading hpack-3.0.0-py2.py3-none-any.whl (38 kB)\n",
            "Building wheels for collected packages: googletrans\n",
            "  Building wheel for googletrans (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for googletrans: filename=googletrans-4.0.0rc1-py3-none-any.whl size=17395 sha256=ce909ece45d291c2182093f069fe8dbdf4d9e8e10c9ad78c6a7b83e1442535ea\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/59/9f/7372f0cf70160fe61b528532e1a7c8498c4becd6bcffb022de\n",
            "Successfully built googletrans\n",
            "Installing collected packages: rfc3986, hyperframe, hpack, h11, chardet, idna, hstspreload, h2, httpcore, httpx, googletrans\n",
            "  Attempting uninstall: chardet\n",
            "    Found existing installation: chardet 5.2.0\n",
            "    Uninstalling chardet-5.2.0:\n",
            "      Successfully uninstalled chardet-5.2.0\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.7\n",
            "    Uninstalling idna-3.7:\n",
            "      Successfully uninstalled idna-3.7\n",
            "Successfully installed chardet-3.0.4 googletrans-4.0.0rc1 h11-0.9.0 h2-3.2.0 hpack-3.0.0 hstspreload-2024.6.1 httpcore-0.9.1 httpx-0.13.3 hyperframe-5.2.0 idna-2.10 rfc3986-1.5.0\n"
          ]
        }
      ],
      "source": [
        "# First, install the googletrans library\n",
        "!pip install googletrans==4.0.0-rc1\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from googletrans import Translator\n",
        "\n",
        "def normalize_text(text):\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9]', '', text)\n",
        "    # Remove vowels\n",
        "    text = re.sub(r'[AEIOUaeiou]', '', text)\n",
        "    # Convert to uppercase\n",
        "    return text.upper()\n",
        "\n",
        "def translate_and_normalize(text):\n",
        "    # Translate text from Bengali to English\n",
        "    translated_text = translator.translate(text, src='bn', dest='en').text\n",
        "    # Normalize the translated text\n",
        "    return normalize_text(translated_text)\n",
        "\n",
        "# Create a translator object\n",
        "translator = Translator()\n",
        "\n",
        "# Load your data (make sure to upload your files to Colab first)\n",
        "data2 = pd.read_excel('/content/Extracted_Physician_Data.xlsx')  # Adjust path as needed\n",
        "data1 = pd.read_excel('/content/M05D28T17Alamin_Missing1.xlsx')  # Adjust path as needed\n",
        "\n",
        "# Apply translation and normalization to the 'Extracted Text'\n",
        "data1['Normalized Extracted Text'] = data1['Extracted Text'].apply(translate_and_normalize)\n",
        "\n",
        "# Normalize the 'PHY_NM' column without translation\n",
        "data2['Normalized PHY_NM'] = data2['PHY_NM'].apply(normalize_text)\n",
        "\n",
        "# Search for matches\n",
        "results = pd.DataFrame(columns=['PHY_NM', 'PHY_ID'])\n",
        "for idx, row in data2.iterrows():\n",
        "    normalized_phy_name = row['Normalized PHY_NM']\n",
        "    mask = data1['Normalized Extracted Text'].str.contains(normalized_phy_name, na=False)\n",
        "    if mask.any():\n",
        "        new_row = pd.DataFrame({'PHY_NM': [row['PHY_NM']], 'PHY_ID': [row['PHY_ID']]})\n",
        "        results = pd.concat([results, new_row], ignore_index=True)\n",
        "\n",
        "# Save the results to an Excel file\n",
        "output_path = '/content/matched_results.xlsx'\n",
        "results.to_excel(output_path, index=False)\n",
        "\n",
        "# Output the path to the saved results\n",
        "print('Results saved to:', output_path)\n",
        "\n",
        "# Code to generate a download link\n",
        "from google.colab import files\n",
        "files.download(output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "zw9BYThXt7sx",
        "outputId": "d0483440-3294-43db-b81f-c23944708fea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to: /content/matched_results.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_710e72d0-ee83-4727-8fcc-f2d3dca850a4\", \"matched_results.xlsx\", 5243)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # First, install the googletrans library\n",
        "# !pip install googletrans==4.0.0-rc1\n",
        "\n",
        "import pandas as pd\n",
        "import re\n",
        "from googletrans import Translator\n",
        "\n",
        "def normalize_text(text):\n",
        "    # Remove special characters\n",
        "    text = re.sub(r'[^a-zA-Z0-9]', '', text)\n",
        "    # Remove vowels\n",
        "    text = re.sub(r'[AEIOUaeiou]', '', text)\n",
        "    # Convert to uppercase\n",
        "    return text.upper()\n",
        "\n",
        "def translate_and_normalize(text):\n",
        "    # Translate text from Bengali to English\n",
        "    translated_text = translator.translate(text, src='bn', dest='en').text\n",
        "    # Normalize the translated text\n",
        "    return normalize_text(translated_text)\n",
        "\n",
        "# Create a translator object\n",
        "translator = Translator()\n",
        "\n",
        "# Load your data (make sure to upload your files to Colab first)\n",
        "data2 = pd.read_excel('/content/Extracted_Physician_Data.xlsx')  # Adjust path as needed\n",
        "data1 = pd.read_excel('/content/M05D28T17Alamin_Missing1.xlsx')  # Adjust path as needed\n",
        "\n",
        "# Apply translation and normalization to the 'Extracted Text'\n",
        "data1['Normalized Extracted Text'] = data1['Extracted Text'].apply(translate_and_normalize)\n",
        "\n",
        "# Normalize the 'PHY_NM' column without translation\n",
        "data2['Normalized PHY_NM'] = data2['PHY_NM'].apply(normalize_text)\n",
        "\n",
        "# Search for matches\n",
        "results = pd.DataFrame(columns=['Image Name', 'Extracted Text', 'PHY_NM', 'PHY_ID'])\n",
        "for idx, row in data2.iterrows():\n",
        "    normalized_phy_name = row['Normalized PHY_NM']\n",
        "    mask = data1['Normalized Extracted Text'].str.contains(normalized_phy_name, na=False)\n",
        "    if mask.any():\n",
        "        # Get rows from data1 where the match is found\n",
        "        matching_rows = data1[mask]\n",
        "        for _, match in matching_rows.iterrows():\n",
        "            new_row = pd.DataFrame({\n",
        "                'Image Name': [match['Image Name']],\n",
        "                'Extracted Text': [match['Extracted Text']],\n",
        "                'PHY_NM': [row['PHY_NM']],\n",
        "                'PHY_ID': [row['PHY_ID']]\n",
        "            })\n",
        "            results = pd.concat([results, new_row], ignore_index=True)\n",
        "\n",
        "# Save the results to an Excel file\n",
        "output_path = '/content/matched_results.xlsx'\n",
        "results.to_excel(output_path, index=False)\n",
        "\n",
        "# Output the path to the saved results\n",
        "print('Results saved to:', output_path)\n",
        "\n",
        "# Code to generate a download link\n",
        "from google.colab import files\n",
        "files.download(output_path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "SDCeT0BrLxbY",
        "outputId": "8ed62031-946d-451b-a380-d6436be9af83"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to: /content/matched_results.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_b0d95ba4-781d-490b-8895-57e56effd06f\", \"matched_results.xlsx\", 13486)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}